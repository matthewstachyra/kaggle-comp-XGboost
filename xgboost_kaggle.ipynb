{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# I. Preliminaries","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport numpy as np\nimport math\nfrom xgboost import XGBClassifier as xgb\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import roc_curve,confusion_matrix,auc\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_sample_weight\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import metrics\nfrom xgboost import plot_importance\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\nfrom sklearn.utils import class_weight\nfrom matplotlib import pyplot\nimport time\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-10-15T18:35:03.887631Z","iopub.execute_input":"2021-10-15T18:35:03.887954Z","iopub.status.idle":"2021-10-15T18:35:04.838187Z","shell.execute_reply.started":"2021-10-15T18:35:03.887923Z","shell.execute_reply":"2021-10-15T18:35:04.837149Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-15T18:35:04.840655Z","iopub.execute_input":"2021-10-15T18:35:04.841028Z","iopub.status.idle":"2021-10-15T18:35:04.850852Z","shell.execute_reply.started":"2021-10-15T18:35:04.840988Z","shell.execute_reply":"2021-10-15T18:35:04.849460Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#download dataset from kaggle and adjust path below\ntrain_data = pd.read_csv('../input/csci-e-82-2021/train_data.csv')\ntest_data = pd.read_csv('../input/csci-e-82-2021/test_data.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-15T18:35:04.853635Z","iopub.execute_input":"2021-10-15T18:35:04.853975Z","iopub.status.idle":"2021-10-15T18:35:06.638180Z","shell.execute_reply.started":"2021-10-15T18:35:04.853935Z","shell.execute_reply":"2021-10-15T18:35:06.637109Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Data Preparation","metadata":{}},{"cell_type":"code","source":"# train_data, test_data -> train, test\n# - drop output column\n# - convert subject, phase, and state to numerical values (one-hot encoding)\n# - drop cols with only one value\n\ntrain = train_data.drop(columns=['output'],axis=1) # drop output col\nsubject_cols = pd.get_dummies(train['subject'], prefix='subject') # one hot encode cols with categorical values\nphase_cols = pd.get_dummies(train['phase'], prefix='phase')\nstate_cols = pd.get_dummies(train['state'], prefix='state')\ntrain = pd.concat([train,subject_cols, phase_cols, state_cols],axis=1) # add one hot encoding\ntrain.drop(['subject', 'phase', 'state'],axis=1, inplace=True) # remove original cols now that we have one hot encoding\n\nsubject_cols_test = pd.get_dummies(test_data['subject'], prefix='subject') # one hot encode cols with categorical values\nphase_cols_test = pd.get_dummies(test_data['phase'], prefix='phase')\nstate_cols_test = pd.get_dummies(test_data['state'], prefix='state')\ntest = pd.concat([test_data,subject_cols_test, phase_cols_test, state_cols_test],axis=1) # do the same for test\ntest.drop(['subject', 'phase', 'state'],axis=1, inplace=True) \n\none_value_col=[]\nfor col in train.columns:\n    if train[col].nunique() == 1:\n        #print(train_data[col].nunique())\n        one_value_col.append(col)\ntrain = train.drop(columns=one_value_col, axis=1)\ntest = test.drop(columns=one_value_col, axis=1)\n\n# drop column which are not important at all\n#drop_feat = ['y19','x32','x29','x27','x23','x19','x16','x13','y167','z27','x133','z25','z23','y171','x80','y175','z19','z16','x158','z183','z180','x196','y13','y23','y25','z106','y27','z80','x209','x184','x172','x183','x180','z162','x174','z171','y80','z174','y16','z13']\n#train = train.drop(columns=drop_feat,axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-15T18:35:06.640352Z","iopub.execute_input":"2021-10-15T18:35:06.640776Z","iopub.status.idle":"2021-10-15T18:35:07.066412Z","shell.execute_reply.started":"2021-10-15T18:35:06.640741Z","shell.execute_reply":"2021-10-15T18:35:07.065361Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Split train data set","metadata":{}},{"cell_type":"code","source":"X = train\ny = train_data['output']\n\n# get subset of cols that are not the one hot encodings\nnumeric_feat = list(set(train.columns) - set(train.iloc[:, 558:].columns))\n\n# standardize X\nscale = StandardScaler()\nX[numeric_feat] = scale.fit_transform(X[numeric_feat])\n\n# split \nX_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.25,stratify=y)\nX_test = test\n\n# standard splits \nX_train[numeric_feat] = scale.fit_transform(X_train[numeric_feat])\nX_val[numeric_feat] = scale.transform(X_val[numeric_feat])\nX_test[numeric_feat] = scale.transform(test[numeric_feat])","metadata":{"execution":{"iopub.status.busy":"2021-10-15T18:35:07.068215Z","iopub.execute_input":"2021-10-15T18:35:07.068596Z","iopub.status.idle":"2021-10-15T18:35:09.136227Z","shell.execute_reply.started":"2021-10-15T18:35:07.068557Z","shell.execute_reply":"2021-10-15T18:35:09.135199Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Define class weight","metadata":{}},{"cell_type":"code","source":"classes_weights = class_weight.compute_class_weight('balanced',\n                                             np.unique(y_train),\n                                             y_train)\nweight = {0: 0.80 , 1: 0.20}\nsample_weight=compute_sample_weight(\"balanced\", y_train)\n\n#sample_weight=compute_sample_weight(\"balanced\", y)\n#sample_weight = y_train.apply(lambda x : weight[x])","metadata":{"execution":{"iopub.status.busy":"2021-10-15T18:35:09.138467Z","iopub.execute_input":"2021-10-15T18:35:09.138854Z","iopub.status.idle":"2021-10-15T18:35:09.151124Z","shell.execute_reply.started":"2021-10-15T18:35:09.138796Z","shell.execute_reply":"2021-10-15T18:35:09.150089Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"y_train.value_counts()\nscale_pos_weight=533/2905\nscale_pos_weight","metadata":{"execution":{"iopub.status.busy":"2021-10-15T18:35:09.152935Z","iopub.execute_input":"2021-10-15T18:35:09.153276Z","iopub.status.idle":"2021-10-15T18:35:09.166489Z","shell.execute_reply.started":"2021-10-15T18:35:09.153234Z","shell.execute_reply":"2021-10-15T18:35:09.165230Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# II. Approach","metadata":{}},{"cell_type":"markdown","source":"## We will be working exclusively with XGBoost. (We tested RFC and it gave poorer performance than XGBoost despite tuning).\n\n1. Plot baseline XGBoost model\n2. Assess baseline performance and understand feature importance\n3. Test core hyperparamters (# of trees and depth of trees) using accuracy and f1 score\n4. Optimize model\n5. Retest feature importance for optimized model\n6. Test optimal threshold (to help with imbalaned data, as is here)\n","metadata":{}},{"cell_type":"markdown","source":"# III. XGBoost Tuning","metadata":{}},{"cell_type":"markdown","source":"## XGBoost base model","metadata":{}},{"cell_type":"code","source":"model = xgb(random_state=42)\npreds = model.fit(X_train, y_train).predict(X_val)\nprint('Train accuracy %s:' % model.score(X_train, y_train)) # training accuracy = 1.0\nprint('Validation accuracy %s:' % accuracy_score(preds, y_val)) # validation accuracy = 0.864","metadata":{"execution":{"iopub.status.busy":"2021-10-15T18:35:14.118010Z","iopub.execute_input":"2021-10-15T18:35:14.118301Z","iopub.status.idle":"2021-10-15T18:35:49.661493Z","shell.execute_reply.started":"2021-10-15T18:35:14.118272Z","shell.execute_reply":"2021-10-15T18:35:49.660391Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# plots of feature importance for base model\nfig, ax = plt.subplots(figsize=(24, 10))\nplot_importance(model, ax=ax)\n\nplt.figure(figsize=(24, 10))\nplt.plot(range(len(model.feature_importances_)), model.feature_importances_)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-15T18:35:49.663561Z","iopub.execute_input":"2021-10-15T18:35:49.664456Z","iopub.status.idle":"2021-10-15T18:35:58.809234Z","shell.execute_reply.started":"2021-10-15T18:35:49.664410Z","shell.execute_reply":"2021-10-15T18:35:58.808160Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# observe matrix (easier to view than cluttered plots)\nbase_featimport = model.feature_importances_.reshape((1, 578)) # we want (578, 1)\nbase_featimport = pd.DataFrame(base_featimport, columns=X_train.columns).T\nbase_featimport = base_featimport.sort_values(by=0, ascending=False)\n\n# look at top 25 features\nbase_featimport[:25]","metadata":{"execution":{"iopub.status.busy":"2021-10-15T18:35:58.810898Z","iopub.execute_input":"2021-10-15T18:35:58.811438Z","iopub.status.idle":"2021-10-15T18:35:58.879676Z","shell.execute_reply.started":"2021-10-15T18:35:58.811393Z","shell.execute_reply":"2021-10-15T18:35:58.878517Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# replot top 25 features\n# we observe there are 5 features that contribute most significantly \nplt.figure(figsize=(24, 10))\nplt.plot(range(len(base_featimport[:25])), base_featimport[:25].to_numpy())\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-15T18:35:58.882772Z","iopub.execute_input":"2021-10-15T18:35:58.883132Z","iopub.status.idle":"2021-10-15T18:35:59.155961Z","shell.execute_reply.started":"2021-10-15T18:35:58.883074Z","shell.execute_reply":"2021-10-15T18:35:59.155025Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# baseline with CV (using original non-split data)\n# purpose: to reduce variance inherent to simpler test/train split approach\n# using stratified CV because classes are imbalanced\nmodel = xgb()\nkfold = StratifiedKFold(n_splits=5, random_state=42)\nresults = cross_val_score(model, X, y, cv=kfold)\nprint(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100)) # 0.863 accuracy close to test/train split run","metadata":{"execution":{"iopub.status.busy":"2021-10-15T18:35:59.159624Z","iopub.execute_input":"2021-10-15T18:35:59.159944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# initial run of hyperparameter tuning\n# testing 3 hyperparameters\n# - n_estimators\n# - max_depth\n# - scale_pos_weight\ndef xgb_param_selection(X, y):\n    n_estimators = [25, 50, 75] # of trees (too large results in overfitting)\n    max_depth=[6, 8] # depth of each tree (too large results in overfitting)\n    scale_pos_weight = [0.18, 0.33] \n    learning_rate = [0.1]\n    objective = ['reg:logistic']\n    param_grid = {'n_estimators': n_estimators, \n                  'max_depth' : max_depth,\n                  'scale_pos_weight':scale_pos_weight, \n                  'learning_rate': learning_rate,\n                  'objective':objective}\n    \n    # build model\n    boost = xgb(use_label_encoder=False)\n    grid_search = RandomizedSearchCV(boost, param_grid, cv=3, n_jobs=-1,verbose=0)\n    grid_search.fit(X, y)\n    grid_search.best_params_\n    return grid_search,grid_search.best_params_\n\nstart_time = time.time()\nxgb_model,xgb_best_prama = xgb_param_selection(X_train,y_train)\nexecution_time = (time.time() - start_time)/60.0\nprint(\"Training execution time (mins)\",execution_time)\nprint('Best param of XGB : ',xgb_best_prama)","metadata":{"execution":{"iopub.status.busy":"2021-10-15T14:47:59.662001Z","iopub.execute_input":"2021-10-15T14:47:59.66261Z","iopub.status.idle":"2021-10-15T14:56:16.760435Z","shell.execute_reply.started":"2021-10-15T14:47:59.662563Z","shell.execute_reply":"2021-10-15T14:56:16.759632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Best param from previous run:  \n# {'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 75, 'objective': 'reg:logistic', 'scale_pos_weight': 0.33}\n# Because the best values for max_depth and n_estimators were the highest in the list,\n# we will test run again with higher values\n\ndef xgb_param_selection(X, y):\n    n_estimators = [75, 100, 150] # of trees (too large results in overfitting)\n    max_depth=[8, 15, 25] # depth of each tree (too large results in overfitting)\n    scale_pos_weight = [0.33, 0.37] \n    learning_rate = [0.1]\n    objective = ['reg:logistic']\n    param_grid = {'n_estimators': n_estimators, \n                  'max_depth' : max_depth,\n                  'scale_pos_weight':scale_pos_weight, \n                  'learning_rate': learning_rate,\n                  'objective':objective}\n    \n    # build model\n    boost = xgb(use_label_encoder=False)\n    grid_search = RandomizedSearchCV(boost, param_grid, cv=3, n_jobs=-1,verbose=0)\n    grid_search.fit(X, y)\n    grid_search.best_params_\n    return grid_search,grid_search.best_params_\n\nstart_time = time.time()\nxgb_model,xgb_best_prama = xgb_param_selection(X_train,y_train)\nexecution_time = (time.time() - start_time)/60.0\nprint(\"Training execution time (mins)\",execution_time)\nprint('Best param of XGB : ',xgb_best_prama)","metadata":{"execution":{"iopub.status.busy":"2021-10-15T14:56:16.761836Z","iopub.execute_input":"2021-10-15T14:56:16.762142Z","iopub.status.idle":"2021-10-15T15:15:14.408818Z","shell.execute_reply.started":"2021-10-15T14:56:16.762098Z","shell.execute_reply":"2021-10-15T15:15:14.408116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# best parameters continue to be:\n# {'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 75, 'objective': 'reg:logistic', 'scale_pos_weight': 0.33}\n# this was unexpected as we thought that increasing the estimators and depth would improve accuracy\n# this yields ~10% improvement in validation accuracy\nmodel = xgb(eta=0.1, max_depth=8, n_estimators=75, objective='reg:logistic', scale_pos_weight=0.33) \npreds = model.fit(X_train, y_train).predict(X_val)\nprint('Train accuracy %s:' % model.score(X_train, y_train)) # training accuracy continues to be 1.00\nprint('Validation accuracy %s:' % accuracy_score(preds, y_val)) # validation accuracy 0.8577","metadata":{"execution":{"iopub.status.busy":"2021-10-15T15:45:31.269088Z","iopub.execute_input":"2021-10-15T15:45:31.269346Z","iopub.status.idle":"2021-10-15T15:45:58.16748Z","shell.execute_reply.started":"2021-10-15T15:45:31.269318Z","shell.execute_reply":"2021-10-15T15:45:58.166716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# testing next:\n# - colsample_bytree [0.5, 0.55, 0.6, 0.65, 0.7, 0.8] -> expect higher colsample to yield better results because...\n# - n_estimators [75, 80, 90] -> re-testing because we change other parameters and this is co-dependent\n# - eval_metric ['error', 'logloss'] -> expect logloss to yield better results as its more appropriate\n# - min_child_weight [0.5, 1, 3, 5]\n# best is (eta=0.1, max_depth=8, n_estimators=75, objective='binary:logistic', scale_pos_weight=0.33, colsample_bytree=0.7, min_child_weight=1) \n\ndef xgb_param_selection(X, y):\n    n_estimators = [75, 80, 90] # of trees (too large results in overfitting)\n    max_depth=[8] # depth of each tree (too large results in overfitting)\n    scale_pos_weight = [0.33] \n    learning_rate = [0.1]\n    objective = ['reg:logistic']\n    eval_metric = ['error', 'logloss']\n    min_child_weight = [0.5, 1, 3, 5]\n    colsample_bytree = [0.5, 0.6, 0.7, 0.8]\n    param_grid = {'n_estimators': n_estimators, \n                  'max_depth' : max_depth,\n                  'scale_pos_weight':scale_pos_weight, \n                  'learning_rate': learning_rate,\n                  'objective':objective, \n                  'eval_metric':eval_metric,\n                  'colsample_bytree':colsample_bytree,\n                  'min_child_weight': min_child_weight}\n    \n    # build model\n    boost = xgb(use_label_encoder=False)\n    grid_search = RandomizedSearchCV(boost, param_grid, cv=3, n_jobs=-1,verbose=0)\n    grid_search.fit(X, y)\n    grid_search.best_params_\n    return grid_search,grid_search.best_params_\n\nstart_time = time.time()\nxgb_model,xgb_best_prama = xgb_param_selection(X, y)\nexecution_time = (time.time() - start_time)/60.0\nprint(\"Training execution time (mins)\",execution_time)\nprint('Best param of XGB : ',xgb_best_prama)","metadata":{"execution":{"iopub.status.busy":"2021-10-15T15:15:41.465894Z","iopub.execute_input":"2021-10-15T15:15:41.466094Z","iopub.status.idle":"2021-10-15T15:28:25.995749Z","shell.execute_reply.started":"2021-10-15T15:15:41.46607Z","shell.execute_reply":"2021-10-15T15:28:25.994929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# best parameters after 2 grid search runs:\n# {'scale_pos_weight': 0.33, 'objective': 'reg:logistic', 'n_estimators': 90, 'min_child_weight': 3, 'max_depth': 8, 'learning_rate': 0.1, 'eval_metric': 'error', 'colsample_bytree': 0.6}\nmodel = xgb(eta=0.1, max_depth=8, n_estimators=90, objective='reg:logistic', scale_pos_weight=0.33, min_child_weight=3, colsample_bytree=0.6, random_state=42, eval_metric='error') \npreds = model.fit(X_train, y_train).predict(X_val) \nprint('Train accuracy: %s' % model.score(X_train, y_train)) \nprint('Validation accuracy: %s' % accuracy_score(preds, y_val)) # validation accuracy 0.866","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# investigating effect of number of trees (n_estimators) on tuned model\nacc_scores = []\nf1_scores = []\nstart_time = time.time()\ntrees = [50, 70, 90, 110, 130, 150]\nfor ne in trees:\n    model = xgb(eta=0.1, max_depth=8, n_estimators=ne, objective='reg:logistic', scale_pos_weight=0.33, min_child_weight=3, colsample_bytree=0.6, eval_metric='logloss') \n    acc_score_list = cross_val_score(model, X, y, cv=3,n_jobs=-1) #returns accuracy\n    f1_score_list = cross_val_score(model, X, y, cv=3, scoring='f1')\n    acc_scores.append(acc_score_list)\n    f1_scores.append(f1_score_list)\nexecution_time = (time.time() - start_time)/60.0\nprint(\"Training execution time (mins)\",execution_time)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot accuracy for # of trees\nbox_df = pd.DataFrame([np.arange(10,150,10), acc_scores]).T\nbox_df.columns = ['numoftrees','acc_score']\nbox_df = pd.DataFrame(np.array(acc_scores))\nbox_df['numoftrees'] = np.arange(10,150,10)\nbox_df = box_df.melt(id_vars='numoftrees')\n\nplt.figure(figsize=(12,5))\nsns.boxplot(x=\"numoftrees\", \n            y=\"value\", \n            data=box_df, \n            showmeans=True);\nplt.xlabel('Number of trees')\nplt.ylabel('Classification score')\nplt.title('Classification score as a function of the number of trees');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot f1 score for # of trees\nbox_df = pd.DataFrame([np.arange(10,150,10), f1_scores]).T\nbox_df.columns = ['numoftrees','f1_score']\nbox_df = pd.DataFrame(np.array(f1_scores))\nbox_df['numoftrees'] = np.arange(10,150,10)\nbox_df = box_df.melt(id_vars='numoftrees')\n\nplt.figure(figsize=(12,5))\nsns.boxplot(x=\"numoftrees\", \n            y=\"value\", \n            data=box_df, \n            showmeans=True);\nplt.xlabel('Number of trees')\nplt.ylabel('F1 score')\nplt.title('F1 score as a function of the number of trees');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find optimal threshold\nyhat = model.predict_proba(X_val)\nyhat = yhat[:, 1] # keep probabilities for the positive outcome only\nfpr, tpr, thresholds = metrics.roc_curve(y_val, yhat) # y_true score, y score\n\n# using Youden's J statistic used to identify best threshold\nJ = tpr - fpr \nix = np.argmax(J)\nopt_thresh = thresholds[ix]\nprint('Optimal predict prob threshold: %f' % (opt_thresh))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generate report for optimal threshold (on X_val)\ndef thresh_pred(model, X, thresh):\n    return (model.predict_proba(X)[:,1] > thresh).astype(int)\n\npred = thresh_pred(model, X_val, opt_thresh)\nprint(metrics.classification_report(y_val, pred))","metadata":{"execution":{"iopub.status.busy":"2021-10-15T18:34:09.165491Z","iopub.status.idle":"2021-10-15T18:34:09.166599Z","shell.execute_reply.started":"2021-10-15T18:34:09.166253Z","shell.execute_reply":"2021-10-15T18:34:09.166288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generate report for optimal threshold (on X)\npred = thresh_pred(model, X, opt_thresh)\nprint(metrics.classification_report(y, pred))","metadata":{"execution":{"iopub.status.busy":"2021-10-15T14:45:08.774652Z","iopub.execute_input":"2021-10-15T14:45:08.774899Z","iopub.status.idle":"2021-10-15T14:45:08.846469Z","shell.execute_reply.started":"2021-10-15T14:45:08.774851Z","shell.execute_reply":"2021-10-15T14:45:08.845291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now we figure out how to generate the submission\n# we submit y_pred (classification guesses based on our X_test)\n# so we need to fit X on our best model\n# and then get predictions using thresh_pred -> which we submit\n\n# ....model code below....\ntest_model = xgb(...)","metadata":{"execution":{"iopub.status.busy":"2021-10-09T16:02:29.098784Z","iopub.execute_input":"2021-10-09T16:02:29.099079Z","iopub.status.idle":"2021-10-09T16:02:29.124638Z","shell.execute_reply.started":"2021-10-09T16:02:29.09905Z","shell.execute_reply":"2021-10-09T16:02:29.12374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.DataFrame()\ny_prob = thresh_pred(test_model, X_test, opt_thresh)\n\nsubmission_df['id'] = range(0,len(X_test))\nsubmission_df['output'] = np.where(y_prob>opt_thresh,1,0)\n\n\nsubmission_df.to_csv('./xg_submission_scale_pos_finetune.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-09T16:02:57.690148Z","iopub.execute_input":"2021-10-09T16:02:57.690473Z","iopub.status.idle":"2021-10-09T16:02:57.73807Z","shell.execute_reply.started":"2021-10-09T16:02:57.690438Z","shell.execute_reply":"2021-10-09T16:02:57.737145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}